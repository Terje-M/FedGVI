{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c8e880-f310-4bec-8c3c-3cac6e2d5ef7",
   "metadata": {},
   "source": [
    "# Logistic Regression with FedGVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa6eff-fa44-4442-882c-084a4d2dfab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from pathlib import Path\n",
    "\n",
    "import math\n",
    "from __future__ import division\n",
    "import copy\n",
    "from statistics import fmean\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch import distributions, nn, optim\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torchvision import transforms, datasets\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fedgvi_experiments.logistic_regression.LogRegExp import LogReg\n",
    "from DSVGD.Bayesian_Logistic_Regression.Methods import Methods\n",
    "from fedgvi_experiments.utils.helper_functions import Gaussian\n",
    "\n",
    "from tueplots import bundles, fonts\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update(fonts.icml2024_tex(family=\"serif\"))\n",
    "#import tqdm.auto as tqdm\n",
    "\n",
    "JITTER = 1e-8\n",
    "\n",
    "%matplotlib inline\n",
    "device = 'cpu'\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_device(device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c2078-8e1b-4d92-8c95-cf7cd66c1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x, y):\n",
    "    x_vals = x[:, 0]\n",
    "    y_vals = x[:, 1]\n",
    "    labels = y\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.grid(visible=True)\n",
    "    plt.scatter(x_vals, y_vals, c=labels)\n",
    "    plt.show()\n",
    "\n",
    "seeds = [2, 13, 21, 42, 71, 97, 151, 227, 331, 397]\n",
    "cs = [(255/255,176/255,0/255),(254/255,97/255,0/255),(220/255,38/255,127/255), \n",
    "      (120/255,94/255,240/255),(100/255,143/255,255/255)]\n",
    "\n",
    "cs2 = [(238/255,119/255,51/255), (0/255,119/255,187/255), (51/255,187/255,238/255),\n",
    "       (238/255,51/255,119/255), (204/255,51/255,17/255), (0/255,153/255,136/255)]\n",
    "\n",
    "\n",
    "def min_max_avg_validation(list_):\n",
    "    min_ = []\n",
    "    max_ = []\n",
    "    avg = []\n",
    "    iters = []\n",
    "    for i in range(len(list_[0][\"validation\"])):\n",
    "        iters.append(i+1)\n",
    "        val = []\n",
    "        val_4_i = []\n",
    "        val_5_i = []\n",
    "        for j in range(len(list_)):\n",
    "            val.append(list_[j][\"validation\"][i])\n",
    "        min_.append(min(val))\n",
    "        max_.append(max(val))\n",
    "        avg.append(fmean(val))\n",
    "    return [min_, max_, avg]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60fd30-78bc-4925-98ae-e771fe928c96",
   "metadata": {},
   "source": [
    "## FedGVI - Covertype Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b413307-8209-4d1a-a96c-3136bc4116ba",
   "metadata": {},
   "source": [
    "#### 2 Clients averaged over 10 train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9187040-5921-4f2c-9978-f69cd38e972c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.1)\n",
    "s = a.sample((100,))\n",
    "run3 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=2,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,#w^Tx+b if true, w^Tx otherwise\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.2},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=500,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                diff_prior_cov = None,# torch.tensor([1/s.mean()]),\n",
    "                client_div = \"KLD\",\n",
    "                client_div_param = 1.0,\n",
    "                client_loss = \"nll\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = None,\n",
    "                seed=seed_)\n",
    "    run3.append(ret)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41855f2f-9c63-4961-86ea-c707093f8126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "run4 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=2,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.6},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=500,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                diff_prior_cov = torch.tensor([1 / s.mean()]),\n",
    "                client_div = \"AR\",\n",
    "                client_div_param = 2.5,\n",
    "                client_loss = \"nll\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = None,\n",
    "                seed=seed_)\n",
    "    run4.append(ret)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b519b98-9d4d-44e3-92a0-c2da5b843a93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "run5 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=2,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.6},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=500,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                diff_prior_cov = torch.tensor([1 / s.mean()]),\n",
    "                client_div = \"KLD\",\n",
    "                client_div_param = 0.6,\n",
    "                client_loss = \"gen_CE\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = 0.5,\n",
    "                seed=seed_,\n",
    "                global_div=\"KLD\",\n",
    "                global_div_param=None)\n",
    "    run5.append(ret)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a93723-b9b7-417e-8270-ea0e0aa13db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "run5_1 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=2,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.6},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=500,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                #diff_prior_cov = torch.tensor([1 / s.mean()]),\n",
    "                client_div = \"KLD\",\n",
    "                client_div_param = 0.6,\n",
    "                client_loss = \"density_power\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = 0.5,\n",
    "                seed=seed_,\n",
    "                global_div=\"KLD\",\n",
    "                global_div_param=None)\n",
    "    run5_1.append(ret)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea30e7-ff2c-440b-a96e-88c45ae5b5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "run5_2 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=2,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.6},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=500,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                #diff_prior_cov = torch.tensor([1 / s.mean()]),\n",
    "                client_div = \"KLD\",\n",
    "                client_div_param = 0.6,\n",
    "                client_loss = \"gamma_mislabel\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = 0.75,\n",
    "                seed=seed_,\n",
    "                global_div=\"KLD\",\n",
    "                global_div_param=None)\n",
    "    run5_2.append(ret)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9b6c0-39f5-42d3-a60a-cfb07920e8d5",
   "metadata": {},
   "source": [
    "#### Plot 2 Client Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bc473-bd52-460a-bf38-165fa87268d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min3, max3, min4, max4, min5, max5 = [],[],[],[],[],[]\n",
    "avg3, avg4, avg5 = [], [], []\n",
    "iters = []\n",
    "for i in range(10):\n",
    "    iters.append(i+1)\n",
    "    val_3_i = []\n",
    "    val_4_i = []\n",
    "    val_5_i = []\n",
    "    for j in range(len(seeds)):\n",
    "        val_3_i.append(run3[j][\"validation\"][i])\n",
    "        val_4_i.append(run4[j][\"validation\"][i])\n",
    "        val_5_i.append(run5[j][\"validation\"][i])\n",
    "    min3.append(min(val_3_i))\n",
    "    max3.append(max(val_3_i))\n",
    "    min4.append(min(val_4_i))\n",
    "    max4.append(max(val_4_i))\n",
    "    min5.append(min(val_5_i))\n",
    "    max5.append(max(val_5_i))\n",
    "    avg3.append(fmean(val_3_i))\n",
    "    avg4.append(fmean(val_4_i))\n",
    "    avg5.append(fmean(val_5_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08104074-3ab8-4377-8614-4a9a21f9bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.25), dpi = 200)\n",
    "    ax.plot(iters,avg3, marker='D', label=r\"PVI\")\n",
    "    ax.fill_between(iters, min3, max3, alpha=0.3)\n",
    "    ax.plot(iters,avg4, marker='o', label=r\"$D_{AR}^{(5)}$\")\n",
    "    ax.fill_between(iters, min4, max4, alpha=0.3)\n",
    "    ax.plot(iters,avg5, marker='^', label=r\"$\\mathcal{L}_{GCE}^{(0.5)}$\")\n",
    "    ax.fill_between(iters, min5, max5, alpha=0.3)\n",
    "    ax.set_xlabel(r\"Server Iterations $t$\")\n",
    "    ax.set_ylabel(r\"Classification Accuracy\")\n",
    "    ax.legend(loc=\"lower right\", frameon=True)\n",
    "    plt.grid(visible=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8ced2-de7f-4737-8910-7af13a15ee41",
   "metadata": {},
   "source": [
    "#### 1 Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c7fb6-de4e-45f0-8e99-94585bb947b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#VI\n",
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "run6 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=1,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,#w^Tx+b if true, w^Tx otherwise\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.2},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=5000,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                diff_prior_cov = torch.tensor([1/s.mean()]),\n",
    "                client_div = \"KLD\",\n",
    "                client_div_param = 0.5,\n",
    "                client_loss = \"nll\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = None,\n",
    "                seed=seed_)\n",
    "    run6.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cceb9a-99e5-47fe-8e50-9390211b7cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GVI\n",
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.1)\n",
    "s = a.sample((100,))\n",
    "run7 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=1,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.2},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=5000,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                diff_prior_cov = torch.tensor([1 / s.mean()]),\n",
    "                client_div = \"AR\",\n",
    "                client_div_param = 5,\n",
    "                client_loss = \"nll\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = None,\n",
    "                seed=seed_)\n",
    "    run7.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2acc8-9860-4ff8-8b07-64c5eae4ff71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GVI_2\n",
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.1)\n",
    "s = a.sample((100,))\n",
    "run8 = []\n",
    "for seed_ in seeds:\n",
    "    print(\"Round \", seeds.index(seed_) + 1)\n",
    "    ret = LogReg().run(num_clients=1,\n",
    "                data_set=\"covertype\",\n",
    "                augment=True,\n",
    "                train_test_split = 0.2,\n",
    "                contamination={\"contaminate\": False, \"type\": None, \"epsilon\": 0.2},\n",
    "                heterogeneity=False,\n",
    "                server_iterations=10,\n",
    "                optim_epochs=5000,\n",
    "                lr = 0.01,\n",
    "                monte_carlo_samples=150,\n",
    "                minibatch_size = 1024,\n",
    "                client_batch_frac = 1.0,\n",
    "                diff_prior_loc = None,\n",
    "                diff_prior_cov = torch.tensor([1 / s.mean()]),\n",
    "                client_div = \"KLD\",\n",
    "                client_div_param = 1,\n",
    "                client_loss = \"gen_CE\",\n",
    "                client_score_fct = None,\n",
    "                client_loss_param = 0.75,\n",
    "                seed=seed_)\n",
    "    run8.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d6b3b-d738-4dbe-9e10-4c62b7b25b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "min6, max6, min7, max7, min8, max8 = [],[],[],[],[],[]\n",
    "avg6, avg7, avg8 = [], [], []\n",
    "iters = []\n",
    "for i in range(len(seeds)):\n",
    "    iters.append(i+1)\n",
    "    val_6_i = []\n",
    "    val_7_i = []\n",
    "    val_8_i = []\n",
    "    for j in range(len(seeds)):\n",
    "        val_6_i.append(run6[j][\"validation\"][i])\n",
    "        val_7_i.append(run7[j][\"validation\"][i])\n",
    "        val_8_i.append(run8[j][\"validation\"][i])\n",
    "    min6.append(min(val_6_i))\n",
    "    max6.append(max(val_6_i))\n",
    "    min7.append(min(val_7_i))\n",
    "    max7.append(max(val_7_i))\n",
    "    min8.append(min(val_8_i))\n",
    "    max8.append(max(val_8_i))\n",
    "    avg6.append(fmean(val_6_i))\n",
    "    avg7.append(fmean(val_7_i))\n",
    "    avg8.append(fmean(val_8_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af359927-fcec-4149-880d-eea6cc7d37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.25), dpi = 200)\n",
    "    \n",
    "    ax.plot(iters,avg3, marker='D', label=r\"PVI\")\n",
    "    ax.fill_between(iters, min3, max3, alpha=0.3)\n",
    "    ax.plot(iters,avg4, marker='o', label=r\"FedGVI, $D_{AR}^{(5)}$\")\n",
    "    ax.fill_between(iters, min4, max4, alpha=0.3)\n",
    "    ax.plot(iters,avg5, marker='^', label=r\"FedGVI, $\\mathcal{L}_{GCE}^{(0.5)}$\")\n",
    "    ax.fill_between(iters, min5, max5, alpha=0.3)\n",
    "    \n",
    "    ax.plot(iters,avg6, marker='s', label=r\"VI\")\n",
    "    ax.fill_between(iters, min6, max6, alpha=0.3)\n",
    "    ax.plot(iters,avg7, marker='p', label=r\"GVI, $D_{AR}^{(5)}$\")\n",
    "    ax.fill_between(iters, min7, max7, alpha=0.3)\n",
    "    ax.plot(iters,avg8, marker='v', label=r\"GVI, $\\mathcal{L}_{GCE}^{(0.5)}$\")\n",
    "    ax.fill_between(iters, min8, max8, alpha=0.3)\n",
    "    \n",
    "    ax.set_xlabel(r\"Server Iterations $t$\")\n",
    "    ax.set_ylabel(r\"Classification Accuracy\")\n",
    "    ax.legend(loc=\"lower right\", frameon=True, ncol=2)\n",
    "    plt.grid(visible=True)\n",
    "    fig.savefig('./figs/log_reg_fedgvi_vi.pgf', format=\"pgf\", bbox_inches= \"tight\", pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8173dd-a77a-417f-8e86-4adda0c5dfd5",
   "metadata": {},
   "source": [
    "#### ROC and AUC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58398c1-54cd-49e5-b2df-5b0b8e6bff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('./../data/covertype.mat')\n",
    "X_input_ = data['covtype'][:, 1:]\n",
    "\n",
    "X_input = np.column_stack((np.ones(len(X_input_)), X_input_))# If w^T X + b is desired\n",
    "\n",
    "y_input = data['covtype'][:, 0]\n",
    "y_input[y_input == 2] = 0  # ensure labels are in {0, 1} otherwise logistic loss breaks but we relabel as needed\n",
    "\n",
    "data_set = {\n",
    "    \"x\": torch.tensor(X_input),\n",
    "    \"y\": torch.tensor(y_input),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35a254-3c46-4ee4-ad0f-1761fea2a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = run3[7][\"q\"][\"loc\"].detach()\n",
    "sigma1 = run3[7][\"q\"][\"var\"].detach()\n",
    "mu2 = run5[6][\"q\"][\"loc\"].detach()\n",
    "sigma2 = run5[6][\"q\"][\"var\"].detach()\n",
    "mu3 = run4[2][\"q\"][\"loc\"].detach()\n",
    "sigma3 = run4[2][\"q\"][\"var\"].detach()\n",
    "probabilities_run3 = []\n",
    "probabilities_run5 = []\n",
    "probabilities_run4 = []\n",
    "for j in range(2):\n",
    "    if j == 0:\n",
    "        mu= mu1\n",
    "        sigma=sigma1\n",
    "    elif j == 1:\n",
    "        mu = mu2\n",
    "        sigma=sigma2\n",
    "    elif j == 2:\n",
    "        mu = mu3\n",
    "        sigma=sigma3\n",
    "    for i in tqdm (range(len(data_set[\"y\"])), desc=\"Validating\", colour='green'):\n",
    "        assert data_set[\"y\"][i] == 0 or data_set[\"y\"][i] == 1, \"Not {0,1} loss labels.\"\n",
    "    \n",
    "        x = data_set[\"x\"][i]\n",
    "        z = (mu @ x) / torch.sqrt(1 + np.pi * (x @ torch.diag(sigma) @ x))\n",
    "        apx_sigmoid = torch.special.expit(z)\n",
    "        \n",
    "        if math.isnan(apx_sigmoid):\n",
    "            print(\"NaN encountered\", i, \"\\n\", data_set[\"x\"][i])\n",
    "            break\n",
    "        if j == 0:\n",
    "            probabilities_run3.append(apx_sigmoid)\n",
    "        elif j==1:\n",
    "            probabilities_run5.append(apx_sigmoid)\n",
    "        elif j==2:\n",
    "            probabilities_run4.append(apx_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb923c-979f-4c48-8720-46557d2829d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pvi_auc = roc_auc_score(y_input, torch.tensor(probabilities_run3))\n",
    "fedgvi_loss_auc = roc_auc_score(y_input, torch.tensor(probabilities_run5))\n",
    "fedgvi_div_auc = roc_auc_score(y_input, torch.tensor(probabilities_run4))\n",
    "\n",
    "\"PVI AUC: \", pvi_auc, \". FedGVI with AR Div AUC: \", fedgvi_div_auc, \". FedGVI with GCE AUC: \", fedgvi_loss_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae676b35-086b-4acc-8fc7-7e968c5171b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve FedGVI\n",
    "x_roc_fedgvi = []\n",
    "y_roc_fedgvi = []\n",
    "for pair in Results[1]:\n",
    "    x_roc_fedgvi.append(pair[0])\n",
    "    y_roc_fedgvi.append(pair[1])\n",
    "\n",
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.25), dpi = 200)\n",
    "    \n",
    "    ax.plot(x_roc_fedgvi,y_roc_fedgvi, marker='D', label=r\"FedGVI\")\n",
    "    ax.plot(x_roc_pvi,y_roc_pvi, marker='+', label=r\"PVI\")\n",
    "    \n",
    "    ax.set_xlabel(r\"$1-S_p$\")\n",
    "    ax.set_ylabel(r\"$S_e$\")\n",
    "    ax.legend(loc=\"lower right\", frameon=True, ncol=2)\n",
    "    ax.set_xlim([0.0,1.0])\n",
    "    ax.set_ylim([0.0,1.0])\n",
    "    plt.grid(visible=True)\n",
    "    fig.savefig('./figs/ROC_FedGVI.pgf', format=\"pgf\", bbox_inches= \"tight\", pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f2665-ccb1-49fa-82fb-9ad1ee3e6d45",
   "metadata": {},
   "source": [
    "## Synthetic Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bbc464-0b3d-4c33-94ca-b0409909fdb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "s_run0 = []\n",
    "seed_ = seeds[2]\n",
    "ret = LogReg().run(num_clients=5,\n",
    "            data_set=\"synthetic_4\",\n",
    "            augment=True,#w^Tx+b if true, w^Tx otherwise\n",
    "            train_test_split = 0.0,\n",
    "            contamination={\"contaminate\": False, \"type\": \"adversarial1\", \"epsilon\": 0.05},\n",
    "            heterogeneity=False,\n",
    "            server_iterations=20,\n",
    "            optim_epochs=500,\n",
    "            lr = 0.01,\n",
    "            monte_carlo_samples=100,\n",
    "            minibatch_size = np.inf,\n",
    "            client_batch_frac = 1.0,\n",
    "            diff_prior_loc = None,\n",
    "            diff_prior_cov = torch.tensor([1/s.mean()]),\n",
    "            client_div = \"KLD\",\n",
    "            client_div_param = 1,\n",
    "            client_loss = \"nll\",\n",
    "            client_score_fct = None,\n",
    "            client_loss_param = None,\n",
    "            seed=seed_,\n",
    "            return_data=True)\n",
    "s_run0.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5ecf1-590d-4188-8eea-ddab2e638488",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(-3, 7, 500)\n",
    "y_ = np.linspace(-3, 7, 500)\n",
    "\n",
    "X, Y = np.meshgrid(x_,y_)\n",
    "\n",
    "tx = s_run0[0][\"train_data\"][\"x\"]\n",
    "ty = s_run0[0][\"train_data\"][\"y\"]\n",
    "x_vals = tx[:, 1]\n",
    "y_vals = tx[:, 2]\n",
    "labels = ty\n",
    "\n",
    "mu_s = s_run0[0][\"q\"][\"loc\"]\n",
    "cov_s = s_run0[0][\"q\"][\"var\"]\n",
    "num_samps = 1000\n",
    "thetas = MultivariateNormal(loc=mu_s, covariance_matrix=torch.diag(cov_s)).sample((num_samps,)).numpy()\n",
    "Probs0 = np.zeros_like(X)\n",
    "\n",
    "for theta in thetas:\n",
    "    trial1 = theta[1]*X + theta[2]*Y\n",
    "    trial2 = theta[0] + trial1\n",
    "    trial3 = -trial2\n",
    "    trial4 = np.exp(trial3)\n",
    "    trial5 = 1 + trial4\n",
    "    trial6 = 1 / trial5\n",
    "    #Probs += 1/(1+ np.exp(-(theta[0] + theta[1]*X + theta[2]*Y)))\n",
    "    Probs0 = Probs0 + trial6\n",
    "Probs0 = Probs0/num_samps\n",
    "\n",
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.5), dpi = 200)\n",
    "    plt.grid(visible=True)\n",
    "    ax.scatter(x_vals, y_vals, c=labels)\n",
    "    ax.contour(X,Y,Probs0, levels=[0.2,0.5,0.8], colors=\"red\")\n",
    "    #ax.legend(loc=\"top left\", frameon=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834222a-c0fe-42d8-9725-498cd897f352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "s_run1 = []\n",
    "seed_ = seeds[0]\n",
    "ret = LogReg().run(num_clients=5,\n",
    "            data_set=\"synthetic_4\",\n",
    "            augment=True,#w^Tx+b if true, w^Tx otherwise\n",
    "            train_test_split = None,\n",
    "            contamination={\"contaminate\": True, \"type\": \"adversarial1\", \"epsilon\": 0.05},\n",
    "            heterogeneity=False,\n",
    "            server_iterations=20,\n",
    "            optim_epochs=500,\n",
    "            lr = 0.01,\n",
    "            monte_carlo_samples=100,\n",
    "            minibatch_size = np.inf,\n",
    "            client_batch_frac = 1.0,\n",
    "            diff_prior_loc = None,\n",
    "            diff_prior_cov = torch.tensor([1/s.mean()]),\n",
    "            client_div = \"KLD\",\n",
    "            client_div_param = 1,\n",
    "            client_loss = \"nll\",\n",
    "            client_score_fct = None,\n",
    "            client_loss_param = None,\n",
    "            seed=seed_,\n",
    "            return_data=True)\n",
    "s_run1.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307400c-d224-4848-96b9-ea016c96bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(-3, 7, 500)\n",
    "y_ = np.linspace(-3, 7, 500)\n",
    "\n",
    "X, Y = np.meshgrid(x_,y_)\n",
    "\n",
    "tx = s_run1[0][\"train_data\"][\"x\"]\n",
    "ty = s_run1[0][\"train_data\"][\"y\"]\n",
    "x_vals = tx[:, 1]\n",
    "y_vals = tx[:, 2]\n",
    "labels = ty\n",
    "\n",
    "mu_s = s_run1[0][\"q\"][\"loc\"]\n",
    "cov_s = s_run1[0][\"q\"][\"var\"]\n",
    "num_samps = 1000\n",
    "thetas = MultivariateNormal(loc=mu_s, covariance_matrix=torch.diag(cov_s)).sample((num_samps,)).numpy()\n",
    "Probs = np.zeros_like(X)\n",
    "\n",
    "for theta in thetas:\n",
    "    trial1 = theta[1]*X + theta[2]*Y\n",
    "    trial2 = theta[0] + trial1\n",
    "    trial3 = -trial2\n",
    "    trial4 = np.exp(trial3)\n",
    "    trial5 = 1 + trial4\n",
    "    trial6 = 1 / trial5\n",
    "    #Probs += 1/(1+ np.exp(-(theta[0] + theta[1]*X + theta[2]*Y)))\n",
    "    Probs = Probs + trial6\n",
    "Probs = Probs/num_samps\n",
    "\n",
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.5), dpi = 200)\n",
    "    plt.grid(visible=True)\n",
    "    ax.scatter(x_vals, y_vals, c=labels)\n",
    "    ax.contour(X,Y,Probs, levels=[0.2,0.5,0.8], colors=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a4d80-f0f0-4ee5-a1d7-a1c22d8c584b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "s_run2 = []\n",
    "seed_ = seeds[0]\n",
    "ret = LogReg().run(num_clients=5,\n",
    "            data_set=\"synthetic_4\",\n",
    "            augment=True,#w^Tx+b if true, w^Tx otherwise\n",
    "            train_test_split = 0.0,\n",
    "            contamination={\"contaminate\": True, \"type\": \"adversarial1\", \"epsilon\": 0.05},\n",
    "            heterogeneity=False,\n",
    "            server_iterations=20,\n",
    "            optim_epochs=500,\n",
    "            lr = 0.01,\n",
    "            monte_carlo_samples=100,\n",
    "            minibatch_size = np.inf,\n",
    "            client_batch_frac = 1.0,\n",
    "            diff_prior_loc = None,\n",
    "            diff_prior_cov = torch.tensor([1/s.mean()]),\n",
    "            client_div = \"AR\",\n",
    "            client_div_param = 1.5,\n",
    "            client_loss = \"density_power\",\n",
    "            client_score_fct = None,\n",
    "            client_loss_param = 0.7,\n",
    "            seed=seed_,\n",
    "            return_data=True)\n",
    "s_run2.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24540f84-1e9d-4986-8201-ad9b875cab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(-3, 7, 500)\n",
    "y_ = np.linspace(-3, 7, 500)\n",
    "\n",
    "X, Y = np.meshgrid(x_,y_)\n",
    "\n",
    "tx = s_run2[0][\"train_data\"][\"x\"]\n",
    "ty = s_run2[0][\"train_data\"][\"y\"]\n",
    "x_vals = tx[:, 1]\n",
    "y_vals = tx[:, 2]\n",
    "labels = ty\n",
    "\n",
    "mu_s2 = s_run2[0][\"q\"][\"loc\"]\n",
    "cov_s2 = s_run2[0][\"q\"][\"var\"]\n",
    "\n",
    "num_samps = 1000\n",
    "thetas = MultivariateNormal(loc=mu_s2, covariance_matrix=torch.diag(cov_s2)).sample((num_samps,)).numpy()\n",
    "Probs2 = np.zeros_like(X)\n",
    "\n",
    "for theta in thetas:\n",
    "    trial1 = theta[1]*X + theta[2]*Y\n",
    "    trial2 = theta[0] + trial1\n",
    "    trial3 = -trial2\n",
    "    trial4 = np.exp(trial3)\n",
    "    trial5 = 1 + trial4\n",
    "    trial6 = 1 / trial5\n",
    "    #Probs += 1/(1+ np.exp(-(theta[0] + theta[1]*X + theta[2]*Y)))\n",
    "    Probs2 = Probs2 + trial6\n",
    "Probs2 = Probs2/num_samps\n",
    "\n",
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.5), dpi = 200)\n",
    "    plt.grid(visible=True)\n",
    "    ax.scatter(x_vals, y_vals, c=labels)\n",
    "    ax.contour(X,Y,Probs2, levels=[0.2,0.5,0.8], colors=\"blue\")\n",
    "    ax.contour(X,Y,Probs, levels=[0.2,0.5,0.8], colors=\"red\")\n",
    "    ax.contour(X,Y,Probs0, levels=[0.2,0.5,0.8], colors=\"black\", alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f936c43-2883-4d0c-a79e-eaf01083eccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "s_run3 = []\n",
    "seed_ = seeds[0]\n",
    "ret = LogReg().run(num_clients=5,\n",
    "            data_set=\"synthetic_4\",\n",
    "            augment=True,#w^Tx+b if true, w^Tx otherwise\n",
    "            train_test_split = 0.0,\n",
    "            contamination={\"contaminate\": True, \"type\": \"adversarial1\", \"epsilon\": 0.05},\n",
    "            heterogeneity=False,\n",
    "            server_iterations=20,\n",
    "            optim_epochs=500,\n",
    "            lr = 0.005,\n",
    "            monte_carlo_samples=100,\n",
    "            minibatch_size = np.inf,\n",
    "            client_batch_frac = 1.0,\n",
    "            diff_prior_loc = None,\n",
    "            diff_prior_cov = torch.tensor([1/s.mean()]),\n",
    "            client_div = \"KLD\",\n",
    "            client_div_param = None,\n",
    "            client_loss = \"gamma_mislabel\",\n",
    "            client_score_fct = None,\n",
    "            client_loss_param = 0.7,\n",
    "            seed=seed_,\n",
    "            return_data=True)\n",
    "s_run3.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd2746-c7ef-4cb2-999a-2e49265e7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(-3, 7, 500)\n",
    "y_ = np.linspace(-3, 7, 500)\n",
    "\n",
    "X, Y = np.meshgrid(x_,y_)\n",
    "\n",
    "tx = s_run3[0][\"train_data\"][\"x\"]\n",
    "ty = s_run3[0][\"train_data\"][\"y\"]\n",
    "x_vals = tx[:, 1]\n",
    "y_vals = tx[:, 2]\n",
    "labels = ty\n",
    "\n",
    "mu_s = s_run3[0][\"q\"][\"loc\"]\n",
    "cov_s = s_run3[0][\"q\"][\"var\"]\n",
    "num_samps = 1000\n",
    "thetas = MultivariateNormal(loc=mu_s, covariance_matrix=torch.diag(cov_s)).sample((num_samps,)).numpy()\n",
    "Probs3 = np.zeros_like(X)\n",
    "\n",
    "for theta in thetas:\n",
    "    trial1 = theta[1]*X + theta[2]*Y\n",
    "    trial2 = theta[0] + trial1\n",
    "    trial3 = -trial2\n",
    "    trial4 = np.exp(trial3)\n",
    "    trial5 = 1 + trial4\n",
    "    trial6 = 1 / trial5\n",
    "    #Probs += 1/(1+ np.exp(-(theta[0] + theta[1]*X + theta[2]*Y)))\n",
    "    Probs3 = Probs3 + trial6\n",
    "Probs3 = Probs3/num_samps\n",
    "\n",
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.5), dpi = 200)\n",
    "    plt.grid(visible=True)\n",
    "    ax.scatter(x_vals, y_vals, c=labels)\n",
    "    ax.contour(X,Y,Probs, levels=[0.2,0.5,0.8], colors=\"red\")\n",
    "    ax.contour(X,Y,Probs3, levels=[0.2,0.5,0.8], colors=\"black\")\n",
    "    ax.contour(X,Y,Probs0, levels=[0.2,0.5,0.8], colors=\"black\", alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b3773-3a05-46ef-a4ab-a1c74172c442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.distributions.gamma.Gamma(1,1/0.01)\n",
    "s = a.sample((100,))\n",
    "s_run4 = []\n",
    "seed_ = seeds[0]\n",
    "ret = LogReg().run(num_clients=5,\n",
    "            data_set=\"synthetic_4\",\n",
    "            augment=True,#w^Tx+b if true, w^Tx otherwise\n",
    "            train_test_split = 0.0,\n",
    "            contamination={\"contaminate\": True, \"type\": \"adversarial1\", \"epsilon\": 0.05},\n",
    "            heterogeneity=False,\n",
    "            server_iterations=20,\n",
    "            optim_epochs=500,\n",
    "            lr = 0.005,\n",
    "            monte_carlo_samples=100,\n",
    "            minibatch_size = np.inf,\n",
    "            client_batch_frac = 1.0,\n",
    "            diff_prior_loc = None,\n",
    "            diff_prior_cov = torch.tensor([1/s.mean()]),\n",
    "            client_div = \"KLD\",\n",
    "            client_div_param = None,\n",
    "            client_loss = \"gen_CE\",\n",
    "            client_score_fct = None,\n",
    "            client_loss_param = 0.7,\n",
    "            seed=seed_,\n",
    "            return_data=True)\n",
    "s_run4.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d915248-9e22-42df-acaa-c2b4d2b1158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(-3, 7, 500)\n",
    "y_ = np.linspace(-3, 7, 500)\n",
    "\n",
    "X, Y = np.meshgrid(x_,y_)\n",
    "\n",
    "tx = s_run4[0][\"train_data\"][\"x\"]\n",
    "ty = s_run4[0][\"train_data\"][\"y\"]\n",
    "x_vals = tx[:, 1]\n",
    "y_vals = tx[:, 2]\n",
    "labels = ty\n",
    "\n",
    "mu_s = s_run4[0][\"q\"][\"loc\"]\n",
    "cov_s = s_run4[0][\"q\"][\"var\"]\n",
    "num_samps = 1000\n",
    "thetas = MultivariateNormal(loc=mu_s, covariance_matrix=torch.diag(cov_s)).sample((num_samps,)).numpy()\n",
    "Probs4 = np.zeros_like(X)\n",
    "\n",
    "for theta in thetas:\n",
    "    \"\"\"trial1 = -(theta[1]*X + theta[2]*Y + theta[0])\n",
    "    trial2 = theta[0] + trial1\n",
    "    trial3 = -trial2\n",
    "    trial4 = np.exp(trial3)\n",
    "    trial5 = 1 + trial4\n",
    "    trial6 = 1 / trial5\"\"\"\n",
    "    Probs4 += 1/(1+ np.exp(-(theta[0] + theta[1]*X + theta[2]*Y)))\n",
    "    #Probs4 = Probs4 + trial6\n",
    "Probs4 = Probs4/num_samps\n",
    "\n",
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.5), dpi = 200)\n",
    "    plt.grid(visible=True)\n",
    "    ax.scatter(x_vals[:100], y_vals[:100], c=labels[:100])\n",
    "    ax.scatter(x_vals[:100], y_vals[:100], c=labels[:100])\n",
    "    ax.scatter(x_vals[100:], y_vals[100:], c=labels[100:], marker='x')\n",
    "    ctr0 = ax.contour(X,Y,Probs0, levels=[0.2,0.5,0.8], colors=\"black\", alpha=.70, linestyles='dashed')\n",
    "    ctr1 = ax.contour(X,Y,Probs, levels=[0.2,0.5,0.8], colors=cs[4])\n",
    "    ctr2 = ax.contour(X,Y,Probs4, levels=[0.2,0.5,0.8], colors=cs[2])\n",
    "    h0, _ = ctr0.legend_elements()\n",
    "    h1, _ = ctr1.legend_elements()\n",
    "    h2, _ = ctr2.legend_elements()\n",
    "    ax.legend([h2[0],h1[0],h0[0]],[r'FedGVI','PVI', 'PVI no outliers'],loc=\"upper left\", frameon=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987d052-1a3b-4ae5-9e14-af4fdcb893e1",
   "metadata": {},
   "source": [
    "#### Plot for Paper\n",
    "\n",
    "Chosen: Density Power Divergence based Loss $L_{GB}^{(0.7)}$ and Alpha- R\\'enyi divergence $D_{AR}^{(1.5)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4acb4-e111-4977-9acb-011c3cdda912",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(-3, 7, 500)\n",
    "y_ = np.linspace(-3, 7, 500)\n",
    "\n",
    "X, Y = np.meshgrid(x_,y_)\n",
    "\n",
    "tx = s_run2[0][\"train_data\"][\"x\"]\n",
    "ty = s_run2[0][\"train_data\"][\"y\"]\n",
    "x_vals = tx[:, 1]\n",
    "y_vals = tx[:, 2]\n",
    "labels = ty.type(torch.int64)\n",
    "\n",
    "label_colors = np.array([cs[4], cs[0]]) \n",
    "\n",
    "cmap, norm = matplotlib.colors.from_levels_and_colors(range(0,3), label_colors)\n",
    "\n",
    "labels_train = np.array(labels[:100])\n",
    "\n",
    "labels_out = np.array(labels[100:])\n",
    "\n",
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 1.75), dpi = 200)\n",
    "    plt.grid(visible=True, alpha=0.8)\n",
    "    sc1 = ax.scatter(x_vals[:100], y_vals[:100], c=labels[:100])\n",
    "    ctr0 = ax.contour(X,Y,Probs0, levels=[0.2,0.5,0.8], colors=\"black\", alpha=.75, linestyles=[(0,(2.25,1.5))])\n",
    "    ctr1 = ax.contour(X,Y,Probs, levels=[0.2,0.5,0.8], colors=cs[1])#, linestyles=[(0,(2.25,1.5))])\n",
    "    sc2 = ax.scatter(x_vals[100:], y_vals[100:], c=labels[100:],cmap=cmap, marker='o')\n",
    "    ctr2 = ax.contour(X,Y,Probs2, levels=[0.2,0.5,0.8], colors=cs[2])\n",
    "    h0, _ = ctr0.legend_elements()\n",
    "    h1, _ = ctr1.legend_elements()\n",
    "    h2, _ = ctr2.legend_elements()\n",
    "    h3, _ = sc2.legend_elements()\n",
    "    h4, _ = sc1.legend_elements()\n",
    "    ax.legend([h2[0],h1[0],h0[0],h4[0],h4[1],h3[0]],[r'FedGVI','PVI', 'PVI w/o Outliers','Class 0','Class 1', 'Outliers Class 0'],\n",
    "              handlelength=2,loc=\"lower right\", frameon=True, borderpad=0.4, fancybox=False, edgecolor=(210/255,210/255,210/255),\n",
    "              framealpha=0.7)\n",
    "    #fig.savefig('./figs/synthetic_log_reg_GB.pgf', format=\"pgf\", bbox_inches= \"tight\", pad_inches=0.0)\n",
    "    #fig.savefig('./figs/synthetic_log_reg_GB.pdf', format=\"pdf\", bbox_inches= \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91730d26-abfc-4280-b938-f759ff0a26f4",
   "metadata": {},
   "source": [
    "## Competing methods for Logistic Regression on the Covertype data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc3739-8388-4588-a2a3-4c5d15479ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_results = Methods().run_competing_methods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31d6f5-2ff4-424f-a043-825490b27907",
   "metadata": {},
   "outputs": [],
   "source": [
    "minDSVGD, maxDSVGD, minFedAvg, maxFedAvg, minDSGLD, maxDSGLD = [],[],[],[],[],[]\n",
    "avgDSVGD, avgFedAvg, avgDSGLD = [], [], []\n",
    "iters = []\n",
    "for i in range(10):\n",
    "    iters.append(i+1)\n",
    "    val_DSVGD_i = []\n",
    "    val_FedAvg_i = []\n",
    "    val_DSGLD_i = []\n",
    "    for j in range(10):\n",
    "        val_DSVGD_i.append(competing_results[\"DSVGD\"][\"validation\"][j][i])\n",
    "        val_FedAvg_i.append(competing_results[\"FedAvg\"][\"validation\"][j][i])\n",
    "        val_DSGLD_i.append(competing_results[\"DSGLD\"][\"validation\"][j][i])\n",
    "    minDSVGD.append(min(val_DSVGD_i))\n",
    "    maxDSVGD.append(max(val_DSVGD_i))\n",
    "    minFedAvg.append(min(val_FedAvg_i))\n",
    "    maxFedAvg.append(max(val_FedAvg_i))\n",
    "    minDSGLD.append(min(val_DSGLD_i))\n",
    "    maxDSGLD.append(max(val_DSGLD_i))\n",
    "    avgDSVGD.append(fmean(val_DSVGD_i))\n",
    "    avgFedAvg.append(fmean(val_FedAvg_i))\n",
    "    avgDSGLD.append(fmean(val_DSGLD_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c0f41-dae7-4647-942b-a7a9b9badb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(bundles.icml2024()):\n",
    "    fig, ax = plt.subplots(figsize = (3.25, 2.25), dpi = 200)\n",
    "    \n",
    "    '''ax.plot(iters,avg6, marker='s', label=r\"VI\")\n",
    "    ax.fill_between(iters, min6, max6, alpha=0.3)\n",
    "    ax.plot(iters,avg7, marker='p', label=r\"GVI, $D_{AR}^{(5)}$\")\n",
    "    ax.fill_between(iters, min7, max7, alpha=0.3)\n",
    "    ax.plot(iters,avg8, marker='v', label=r\"GVI, $\\mathcal{L}_{GCE}^{(0.5)}$\")\n",
    "    ax.fill_between(iters, min8, max8, alpha=0.3)'''\n",
    "\n",
    "\n",
    "    ax.plot(iters,avg3, marker='D', label=r\"PVI\", color=cs2[0])\n",
    "    ax.fill_between(iters, min3, max3, alpha=0.3, facecolor=cs2[0])\n",
    "\n",
    "    ax.plot(iters,avgFedAvg, marker='*', label=r\"FedAvg\", color=cs2[1])\n",
    "    ax.fill_between(iters, minFedAvg, maxFedAvg, alpha=0.3, facecolor=cs2[1])\n",
    "    \n",
    "    ax.plot(iters,avgDSGLD, marker='2', label=r\"DSGLD\", color=cs2[2])\n",
    "    ax.fill_between(iters, minDSGLD, maxDSGLD, alpha=0.3, facecolor=cs2[2])\n",
    "    \n",
    "    ax.plot(iters,avgDSVGD, marker='P', label=r\"DSVGD\", color=cs2[4])\n",
    "    ax.fill_between(iters, minDSVGD, maxDSVGD, alpha=0.3, facecolor=cs2[4])\n",
    "    \n",
    "    ax.plot(iters,avg4, marker='o', label=r\"FedGVI, $D_{AR}^{(5)}$\", color=cs2[5])\n",
    "    ax.fill_between(iters, min4, max4, alpha=0.3, facecolor=cs2[5])\n",
    "    ax.plot(iters,avg5, marker='^', label=r\"FedGVI, $\\mathcal{L}_{GCE}^{(0.5)}$\", color=cs2[3])\n",
    "    ax.fill_between(iters, min5, max5, alpha=0.3, facecolor=cs2[3])\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    order = [0,4,5,1,2,3]\n",
    "    \n",
    "    ax.set_xlabel(r\"Server Iterations $t$\")\n",
    "    ax.set_ylabel(r\"Classification Accuracy\")\n",
    "    ax.legend([handles[i] for i in order], [labels[i] for i in order],loc=\"lower right\", frameon=True, ncol=2)\n",
    "    ax.set_ylim([0.64,0.775])\n",
    "    plt.grid(visible=True)\n",
    "    fig.savefig('./figs/log_reg_fedgvi_competing.pgf', format=\"pgf\", bbox_inches= \"tight\", pad_inches=0)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
